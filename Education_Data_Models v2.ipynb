{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A model for math and reading proficiency in US school districts from 2009-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individuals with low reading proficiency are more likely to drop-out of high school, to end up in the criminal justice system, and to live in poverty. Even more, the lack of high school education is a powerful predictor of mortality variation among US states and high school dropouts make up disproportionately higher percentages of the nation’s institutionalized population than of the nation’s noninstitutionalized population, so low achievement in math and reading proficiency could be the start of a much larger issue.\n",
    "\n",
    "To understand the different levels of proficiency, we used features X, Y, Z in various models with the intent to answer the question of how does instructional spend from 2009-2016 spend impact math and reading proficiency amongst different demographics (e.g., race, gender, and socioeconomic status), as we hypothesize that achievement is determined by instructional expenditure.\n",
    "\n",
    "Our findings show that: i) xxxxxxxx, ii) xxxxxxx, and iii) xxxxxx. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education Data Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains two models that predict educational outcomes based on instructional spend per district from 2009 to 2018. We use using publically available data by the Education Department.\n",
    "The following featues are included:\n",
    "- gender\n",
    "- grade\n",
    "- race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Data\n",
    "This dataframe  contains district level finance data including revenues from federal, state, and local governments and expenditures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>leaid</th>\n",
       "      <th>fips</th>\n",
       "      <th>censusid</th>\n",
       "      <th>rev_total</th>\n",
       "      <th>exp_total</th>\n",
       "      <th>exp_current_instruction_total</th>\n",
       "      <th>enrollment_fall_responsible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258542</th>\n",
       "      <td>2009</td>\n",
       "      <td>0100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258543</th>\n",
       "      <td>2009</td>\n",
       "      <td>0100005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.504840e+12</td>\n",
       "      <td>38927000.0</td>\n",
       "      <td>57286000.0</td>\n",
       "      <td>20908000.0</td>\n",
       "      <td>4104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258544</th>\n",
       "      <td>2009</td>\n",
       "      <td>0100006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.504800e+12</td>\n",
       "      <td>57766000.0</td>\n",
       "      <td>57101000.0</td>\n",
       "      <td>29908000.0</td>\n",
       "      <td>5777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258545</th>\n",
       "      <td>2009</td>\n",
       "      <td>0100007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.503740e+12</td>\n",
       "      <td>149924000.0</td>\n",
       "      <td>152411000.0</td>\n",
       "      <td>83430000.0</td>\n",
       "      <td>12889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258546</th>\n",
       "      <td>2009</td>\n",
       "      <td>0100008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.504530e+12</td>\n",
       "      <td>85030000.0</td>\n",
       "      <td>85734000.0</td>\n",
       "      <td>44662000.0</td>\n",
       "      <td>8654.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year    leaid  fips      censusid    rev_total    exp_total  \\\n",
       "258542  2009  0100002   1.0 -2.000000e+00         -2.0         -2.0   \n",
       "258543  2009  0100005   1.0  1.504840e+12   38927000.0   57286000.0   \n",
       "258544  2009  0100006   1.0  1.504800e+12   57766000.0   57101000.0   \n",
       "258545  2009  0100007   1.0  1.503740e+12  149924000.0  152411000.0   \n",
       "258546  2009  0100008   1.0  1.504530e+12   85030000.0   85734000.0   \n",
       "\n",
       "        exp_current_instruction_total  enrollment_fall_responsible  \n",
       "258542                           -2.0                          0.0  \n",
       "258543                     20908000.0                       4104.0  \n",
       "258544                     29908000.0                       5777.0  \n",
       "258545                     83430000.0                      12889.0  \n",
       "258546                     44662000.0                       8654.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_df = pd.read_csv(\"financial/districts_ccd_finance.csv.gz\",compression='gzip')\n",
    "finance_df.head(5)\n",
    "\n",
    "# only keep columns we are interested in\n",
    "finance_df = finance_df[['year', 'leaid', 'fips', 'censusid', 'rev_total', 'exp_total', \n",
    "                                             'exp_current_instruction_total', 'enrollment_fall_responsible']]\n",
    "\n",
    "finance_df = finance_df[finance_df.year > 2008]\n",
    "\n",
    "finance_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District Directory Data\n",
    "This dataframe contains school district geographic and mailing information, agency type, highest and lowest grades offered, special education students and English language learners, and full-time equivalent teachers and other staff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_2009_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2009.csv\", compression='gzip')\n",
    "directory_2010_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2010.csv\", compression='gzip')\n",
    "directory_2011_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2011.csv\", compression='gzip')\n",
    "directory_2012_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2012.csv\", compression='gzip')\n",
    "directory_2014_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2014.csv\", compression='gzip')\n",
    "directory_2015_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2015.csv\", compression='gzip')\n",
    "directory_2016_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2016.csv\", compression='gzip')\n",
    "directory_2017_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2017.csv\", compression='gzip')\n",
    "directory_2018_df = pd.read_csv(\"district_directory/school-districts_lea_directory_2018.csv\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'directory_2013_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-42287337435c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# missing concatenation in overall directory df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m directory_df = pd.concat([directory_2009_df, directory_2010_df, directory_2011_df, directory_2012_df,\n\u001b[0;32m----> 3\u001b[0;31m                          \u001b[0mdirectory_2013_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory_2014_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory_2015_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory_2016_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                          directory_2017_df, directory_2018_df], axis=0)\n\u001b[1;32m      5\u001b[0m \u001b[0mdirectory_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'directory_2013_df' is not defined"
     ]
    }
   ],
   "source": [
    "# missing concatenation in overall directory df\n",
    "directory_df = pd.concat([directory_2009_df, directory_2010_df, directory_2011_df, directory_2012_df,\n",
    "                         directory_2013_df, directory_2014_df, directory_2015_df, directory_2016_df,\n",
    "                         directory_2017_df, directory_2018_df], axis=0)\n",
    "directory_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_df = directory_df[['year', 'leaid', 'lea_name', 'state_leaid','state_location', 'zip_location', 'fips', \n",
    "                             'county_code', 'county_name', 'latitude', 'longitude', 'urban_centric_locale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_2009_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2009.csv\", compression='gzip')\n",
    "edfacts_2010_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2010.csv\", compression='gzip')\n",
    "edfacts_2011_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2011.csv\", compression='gzip')\n",
    "edfacts_2012_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2012.csv\", compression='gzip')\n",
    "edfacts_2013_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2013.csv\", compression='gzip')\n",
    "edfacts_2014_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2014.csv\", compression='gzip')\n",
    "edfacts_2015_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2015.csv\", compression='gzip')\n",
    "edfacts_2016_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2016.csv\", compression='gzip')\n",
    "edfacts_2017_df = pd.read_csv(\"district_edfacts/districts_edfacts_assessments_2017.csv\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edfacts_df = pd.concat([edfacts_2009_df, edfacts_2010_df, edfacts_2011_df, edfacts_2012_df,\n",
    "                         edfacts_2013_df, edfacts_2014_df, edfacts_2015_df, edfacts_2016_df,\n",
    "                         edfacts_2017_df], axis=0)\n",
    "edfacts_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edfacts_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_df = edfacts_df[['leaid', 'leaid_num', 'year', 'lea_name', 'fips', 'grade_edfacts', 'race', 'sex', 'lep', \n",
    "                         'homeless', 'migrant', 'disability', 'econ_disadvantaged', 'foster_care', 'military_connected', \n",
    "                         'read_test_num_valid', 'read_test_pct_prof_low', 'read_test_pct_prof_high', \n",
    "                         'read_test_pct_prof_midpt', 'math_test_num_valid', 'math_test_pct_prof_low', \n",
    "                         'math_test_pct_prof_high', 'math_test_pct_prof_midpt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not sure we need enrollment df when race is included in edfacts (I'm using it, but calling it out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_2009_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2009.csv\", compression='gzip')\n",
    "enrollment_2010_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2010.csv\", compression='gzip')\n",
    "enrollment_2011_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2011.csv\", compression='gzip')\n",
    "enrollment_2012_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2012.csv\", compression='gzip')\n",
    "enrollment_2013_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2013.csv\", compression='gzip')\n",
    "enrollment_2014_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2014.csv\", compression='gzip')\n",
    "enrollment_2015_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2015.csv\", compression='gzip')\n",
    "enrollment_2016_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2016.csv\", compression='gzip')\n",
    "enrollment_2017_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2017.csv\", compression='gzip')\n",
    "enrollment_2018_df = pd.read_csv(\"district_enrollment/schools_ccd_lea_enrollment_2018.csv\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>leaid</th>\n",
       "      <th>fips</th>\n",
       "      <th>grade</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   leaid  fips  grade  race  sex  enrollment\n",
       "0  2009  100002     1      3     1    1         0.0\n",
       "1  2009  100002     1      3     1    2         0.0\n",
       "2  2009  100002     1      3     1   99         0.0\n",
       "3  2009  100002     1      3     2    1         0.0\n",
       "4  2009  100002     1      3     2    2         0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "enroll_df = pd.concat([enrollment_2009_df, enrollment_2010_df, enrollment_2011_df, enrollment_2012_df,\n",
    "                         enrollment_2013_df, enrollment_2014_df, enrollment_2015_df, enrollment_2016_df,\n",
    "                         enrollment_2017_df, enrollment_2018_df], axis=0)\n",
    "enroll_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enroll_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a566a897ff07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menroll_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'enroll_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(enroll_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'directory_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a2201d61dc23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# merging directory, edfacts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmaster_temp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medfacts_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'directory_df' is not defined"
     ]
    }
   ],
   "source": [
    "# merging directory, edfacts\n",
    "master_temp_df = pd.merge(directory_df, edfacts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging (directory, edfacts) with enroll\n",
    "master_temp2_df = pd.merge(master_temp_df, enroll_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.merge(master_temp2_df, finance_df)\n",
    "# Todo: refactor to use join. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(master_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Instructional Spend Per Student Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[\"total_spend_per_student\"] = master_df[ \"exp_total\"] / master_df[ \"enrollment_fall_responsible\"]\n",
    "master_df[\"instruction_spend_per_student\"] = master_df[ \"exp_current_instruction_total\"] / master_df[ \"enrollment_fall_responsible\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data Frame\n",
    "0. Remove NaN\n",
    "1. Only keep positive numbers,  exclude lat, long\n",
    "2. Remove outliers for  instructional total  \n",
    "3. Remove districts that have less than 100 students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_cleaned = master_df.dropna()\n",
    "\n",
    "def cleanup_data(dataframe):\n",
    "    \"\"\"Clean up dataframe returns a dataframe\"\"\"\n",
    "    \n",
    "    numerical_columns = ['grade_edfacts', 'race', 'sex', 'lep', \n",
    "                         'homeless', 'migrant', 'disability', \n",
    "                         'econ_disadvantaged', 'foster_care', \n",
    "                         'military_connected', 'read_test_num_valid',\n",
    "                         'read_test_pct_prof_low', 'read_test_pct_prof_high',\n",
    "                         'read_test_pct_prof_midpt', 'math_test_num_valid', \n",
    "                         'math_test_pct_prof_low', 'math_test_pct_prof_high', \n",
    "                         'math_test_pct_prof_midpt', 'grade', 'enrollment', \"instruction_spend_per_student\" , \"total_spend_per_student\"]\n",
    "    \n",
    "    \n",
    "    # We only want to keep positive numbers\n",
    "    for column_name in numerical_columns:\n",
    "        dataframe =  dataframe[(dataframe[column_name] >= 0) ]\n",
    "        \n",
    "    # Remove outliers for instructional total   \n",
    "    #dataframe[dataframe['exp_current_instruction_total'] < float('1.646168e+09')]    \n",
    "    \n",
    "    # Only include districts with more than 100 students \n",
    "    #dataframe = dataframe[dataframe['enrollment_fall_responsible'] > 50]\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "cleaned_df = cleanup_data(master_df_cleaned)\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box Plot\n",
    "## Differences between sexes in reading proficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='sex', y = 'read_test_pct_prof_midpt', data = cleaned_df) \n",
    "plt.title(\"Gender vs Reading proficiency mid\");\n",
    "# 1 is male \n",
    "# 2 is female\n",
    "# 99 is Total "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between Races in reading proficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='race', y = 'read_test_pct_prof_midpt', data = grade_12_df) \n",
    "plt.title(\"Race vs Read Prof mid\");\n",
    "\"\"\"\"\"\n",
    "1—White\n",
    "2—Black\n",
    "3—Hispanic\n",
    "4—Asian\n",
    "5—American Indian or Alaska Native\n",
    "6—Native Hawaiian or other Pacific Islander\n",
    "7—Two or more races\n",
    "8—Nonresident alien\n",
    "9—Unknown\n",
    "20—Other\n",
    "99—Total\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test Male and females \n",
    "\n",
    "#https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/t-test/\n",
    "from   scipy import stats\n",
    "\n",
    "## A simple t test for difference of means\n",
    "t2, p2 = stats.ttest_ind(cleaned_df.loc[cleaned_df['sex'] == 1, 'read_test_pct_prof_midpt']\n",
    "                         ,cleaned_df.loc[cleaned_df['sex'] == 2, 'read_test_pct_prof_midpt'])\n",
    "\n",
    "print(\"Reading Test are the Same for Male and females\")\n",
    "print(\"t = \" + str(t2))\n",
    "print(\"p = \" + str(p2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructional Spend Box Plot\n",
    "\n",
    "sns.boxplot(x='race', y = 'instruction_spend_per_student', data = cleaned_df) \n",
    "plt.title(\"instruction_spend_per_student vs race\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix\n",
    "\n",
    "To find the variables that have the greatest influence on read_test_pct_prof_midpt, we can compute a <b>correlation matrix</b> which measures the pairwise correlations between any two variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat  = cleaned_df[[ \"total_spend_per_student\", \"instruction_spend_per_student\" ,'grade_edfacts', 'race', 'sex', 'lep', 'homeless', 'migrant', 'disability', 'econ_disadvantaged','read_test_num_valid', 'read_test_pct_prof_low', 'read_test_pct_prof_high', 'read_test_pct_prof_midpt', 'math_test_num_valid', 'math_test_pct_prof_low', 'math_test_pct_prof_high', 'math_test_pct_prof_midpt']].corr()\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_mat,cmap=sns.diverging_palette(220, 10, as_cmap=True))\n",
    "plt.title(\"Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using linear models to account for variables correlated with reading proficiency\n",
    "\n",
    "Once we identify some independent variables that are correlated with the dependent variable, a linear model can be used to capture this relationship quantitatively. A linear model does this by finding a line that [**best fits**](https://mathbits.com/MathBits/TISection/Statistics1/LineFit.htm) the data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'instruction_spend_per_student', y = 'read_test_pct_prof_midpt', data = cleaned_df, scatter_kws = {'color': (174/255,199/255,14/255)})\n",
    "plt.title(\"instruction_spend_per_student vs. read_test_pct_prof_midpt\", fontsize=20, verticalalignment='bottom')\n",
    "plt.xlabel(\"instruction_spend_per_student\")\n",
    "plt.ylabel(\"read_test_pct_prof_midpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Model for Reading proficiency only Grade 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_12_df = cleaned_df[cleaned_df[\"grade\"] == 12]\n",
    "x = grade_12_df[[\"instruction_spend_per_student\", 'lep', 'homeless', 'migrant', 'disability', 'econ_disadvantaged', 'foster_care', 'military_connected','race',\"sex\",'exp_current_instruction_total']]  # add more explanatory variables; \n",
    "y = grade_12_df['read_test_pct_prof_midpt']\n",
    "x = sm.add_constant(x)\n",
    "est = sm.OLS(y, x).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Model for Reading proficiency only (math excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cleaned_df[['lep', 'homeless', 'migrant', 'disability', \n",
    "                'econ_disadvantaged', 'foster_care', \n",
    "                'military_connected','race',\"sex\",\n",
    "                'exp_current_instruction_total']]  \n",
    "\n",
    "y = cleaned_df['read_test_pct_prof_midpt']\n",
    "x = sm.add_constant(x)\n",
    "est = sm.OLS(y, x).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting one single year to better understand how the model is working\n",
    "finance_2015_df = finance_df[finance_df.year == 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting one single year to better understand how the model is working\n",
    "finance_2015_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting one single year to better understand how the model is working\n",
    "edfacts_2015_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this would be disagregated by race (ie, race is not 00)\n",
    "edfacts_2015_by_race_df = edfacts_2015_df[(edfacts_2015_df['sex']== 99)\n",
    "                                       & (edfacts_2015_df['lep']== 99)\n",
    "                                      & (edfacts_2015_df['homeless']== 99)\n",
    "                                      & (edfacts_2015_df['migrant']== 99)\n",
    "                                      & (edfacts_2015_df['disability']== 99)\n",
    "                                      & (edfacts_2015_df['econ_disadvantaged']== 99)\n",
    "                                      & (edfacts_2015_df['foster_care']== 99)\n",
    "                                      & (edfacts_2015_df['military_connected']== 99) \n",
    "                                       & (edfacts_2015_df['grade_edfacts']== 99)]\n",
    "\n",
    "edfacts_2015_without_total_race_df = edfacts_2015_by_race_df[edfacts_2015_by_race_df['race'] != 99]\n",
    "edfacts_2015_without_total_race_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the output above, we see that if the number of valid tests taken is larger than 300, we get the actual percentage of students that scored proficient. If it is smaller than 300, it gets bucketed into ranges for anonimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_by_race_df = [edfacts_2009_df, edfacts_2010_df, edfacts_2011_df, edfacts_2012_df,\n",
    "                         edfacts_2013_df, edfacts_2014_df, edfacts_2015_df, edfacts_2016_df,\n",
    "                         edfacts_2017_df]\n",
    "\n",
    "edfacts_df_dict = defaultdict(list)\n",
    "i = 2009\n",
    "for df in edfacts_by_race_df:\n",
    "    new_df_name = df[(df['sex']== 99)\n",
    "                                       & (df['lep']== 99)\n",
    "                                      & (df['homeless']== 99)\n",
    "                                      & (df['migrant']== 99)\n",
    "                                      & (df['disability']== 99)\n",
    "                                      & (df['econ_disadvantaged']== 99)\n",
    "                                      & (df['foster_care']== 99)\n",
    "                                      & (df['military_connected']== 99) \n",
    "                                       & (df['grade_edfacts']== 99)]\n",
    "    edfacts_df_dict[i] = new_df_name\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_2015_race_df = edfacts_df_dict[2015]\n",
    "edfacts_2015_race_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_2015_race_df['read_test_num_valid'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_2015_race_df['read_test_num_valid'].describe()\n",
    "edfacts_2015_race_df.hist(column='read_test_num_valid', bins=5)\n",
    "edfacts_2015_race_df['read_test_num_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_2015_race_df_drop_read_outlier = edfacts_2015_race_df[(edfacts_2015_race_df['read_test_num_valid'] < float('1000')) \n",
    "                                                              & (edfacts_2015_race_df['race'] == 99)]\n",
    "edfacts_2015_race_df_drop_read_outlier['read_test_num_valid'].describe()\n",
    "edfacts_2015_race_df_drop_read_outlier.hist(column='read_test_num_valid', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all negative entries, which means data is supressed (-1), not applicable (-2), or missing (-3)\n",
    "# we are only focusing on districts w/ over 100 students\n",
    "\n",
    "finance_by_year_df = [edfacts_2009_df, edfacts_2010_df, edfacts_2011_df, edfacts_2012_df,\n",
    "                         edfacts_2013_df, edfacts_2014_df, edfacts_2015_df, edfacts_2016_df,\n",
    "                         edfacts_2017_df]\n",
    "\n",
    "my_values = defaultdict(list)\n",
    "i = 2009\n",
    "for df in edfacts_by_race_df:\n",
    "    new_df_name = df[(df['sex']== 99)\n",
    "                                       & (df['lep']== 99)\n",
    "                                      & (df['homeless']== 99)\n",
    "                                      & (df['migrant']== 99)\n",
    "                                      & (df['disability']== 99)\n",
    "                                      & (df['econ_disadvantaged']== 99)\n",
    "                                      & (df['foster_care']== 99)\n",
    "                                      & (df['military_connected']== 99) \n",
    "                                       & (df['grade_edfacts']== 99)]\n",
    "    my_values[i] = new_df_name\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "finance_2015_clean_df1 = finance_2015_df[(finance_2015_df['rev_total'] > 0) \n",
    "                                       & (finance_2015_df['exp_total'] > 0)\n",
    "                                       & (finance_2015_df['exp_current_instruction_total']> 0)\n",
    "                                      & (finance_2015_df['enrollment_fall_responsible'] > 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_2015_clean_df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_2015_clean_df1.sort_values(by = 'enrollment_fall_responsible', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all negative entries, which means data is supressed (-1), not applicable (-2), or missing (-3)\n",
    "edfacts_2015_clean_df1 = edfacts_2015_race_df[(edfacts_2015_race_df['read_test_pct_prof_low'] > 0) \n",
    "                                       | (edfacts_2015_race_df['read_test_pct_prof_high'] > 0)\n",
    "                                       | (edfacts_2015_race_df['read_test_pct_prof_midpt']> 0)\n",
    "                                      | (edfacts_2015_race_df['math_test_pct_prof_low'] > 0)\n",
    "                                      | (edfacts_2015_race_df['math_test_pct_prof_high'] > 0)\n",
    "                                      | (edfacts_2015_race_df['math_test_pct_prof_midpt'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfacts_2015_clean_df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_clean = pd.merge(finance_2015_clean_df1, edfacts_2015_clean_df1, on = \"leaid\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2015_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_clean_dropna = df_2015_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_2015_clean_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = inputs for prediction; Y = what we are predicting\n",
    "x = df_2015_clean_dropna['exp_current_instruction_total']\n",
    "y = df_2015_clean_dropna['read_test_pct_prof_high']\n",
    "x = sm.add_constant(x)\n",
    "est = sm.OLS(y, x).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_2015_clean_dropna['exp_current_instruction_total'], df_2015_clean_dropna['read_test_pct_prof_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the outlier and drop it\n",
    "df_2015_clean_dropna.sort_values(by='exp_current_instruction_total', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_clean_drop_outlier = df_2015_clean_dropna[df_2015_clean_dropna['exp_current_instruction_total'] < float('1.646168e+09')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_2015_clean_drop_outlier['exp_current_instruction_total'], df_2015_clean_drop_outlier['read_test_pct_prof_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with per capita instructional expenditure per student\n",
    "df_2015_clean_drop_outlier['instructional_exp_per_student'] = df_2015_clean_drop_outlier['exp_current_instruction_total'] / df_2015_clean_drop_outlier['enrollment_fall_responsible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_2015_clean_drop_outlier['instructional_exp_per_student'], df_2015_clean_drop_outlier['read_test_pct_prof_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we see here -1.0 is not really a negative number it is $100M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_clean_drop_outlier['enrollment_fall_responsible'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_2015_clean_drop_outlier.sort_values(by = 'enrollment_fall_responsible', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = inputs for prediction; Y = what we are predicting\n",
    "x = df_2015_clean_drop_outlier['exp_current_instruction_total']\n",
    "y = df_2015_clean_drop_outlier['read_test_pct_prof_high']\n",
    "x = sm.add_constant(x)\n",
    "est = sm.OLS(y, x).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_2015_clean_drop_outlier['exp_current_instruction_total'].tolist() \n",
    "y = df_2015_clean_drop_outlier['read_test_pct_prof_high'].tolist() \n",
    "plt.scatter(x, y) \n",
    "  \n",
    "# finding the maximum and minimum \n",
    "# values of x, to get the \n",
    "# range of data \n",
    "max_x = df_2015_clean_drop_outlier['exp_current_instruction_total'].max() \n",
    "min_x = df_2015_clean_drop_outlier['read_test_pct_prof_high'].min() \n",
    "  \n",
    "# range of values for plotting \n",
    "# the regression line \n",
    "x = np.arange(min_x, max_x, 1) \n",
    "  \n",
    "# the substituted equation \n",
    "y = -3.186e-08 * x - 55.9731\n",
    "  \n",
    "# plotting the regression line \n",
    "plt.plot(y, 'r') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open questions:\n",
    "- I'm failing to add race. Not sure what needs to be done before I can use it since it is a categorical variable\n",
    "- Need to decide on the features we want (correlation amongst them?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features:\n",
    "- From Finance:\n",
    "    - All the dollar amounts here are highly correlated; we likely don't want to get rid of them but they will be highly correlated. We can devide exp_current_instruction total by exp_total to decouple it from the total amount.\n",
    "    - 'rev_total' - Numerical/measurement\n",
    "    - 'exp_total'  - Numerical/measurement \n",
    "    - 'exp_current_instruction_total' - Numerical/measurement \n",
    "    - 'enrollment_fall_responsible' - Numerical/measurement   - get per capita measure on $ spend\n",
    "    \n",
    "- From Directory: For this we should be able to recode\n",
    "    - 'urban_centric_locale': - categorical\n",
    "        1—Large city = city\n",
    "        2—Midsize city = city\n",
    "        3—Urban fringe of large city = city\n",
    "        4—Urban fringe of midsize city = city\n",
    "        5—Large town = town\n",
    "        6—Small town = town\n",
    "        7—Rural, outside CBSA = rural\n",
    "        8—Rural, inside CBSA  = rural\n",
    "        9—Not assigned\n",
    "        11—City, large = city\n",
    "        12—City, midsize = city\n",
    "        13—City, small = city\n",
    "        21—Suburb, large = suburb\n",
    "        22—Suburb, midsize = suburb\n",
    "        23—Suburb, small = suburb\n",
    "        31—Town, fringe = town\n",
    "        32—Town, distant = town\n",
    "        33—Town, remote = town\n",
    "        41—Rural, fringe = rural\n",
    "        42—Rural, distant = rural\n",
    "        43—Rural, remote = rural\n",
    "        \n",
    "- From edfacts: \n",
    "        'grade_edfacts' -  --> Ask OhKyu about this one. For this one, the recommendation is to limit it to school districts with the same grades, otherwise, it will introduce bias. We have to try if the better prediction is by grade (potentially more noisy, and lower grades may be less predictive) or by total. REgardless of which one we chose, we need to be consistent\n",
    "        'race', 'sex', 'lep', \n",
    "         'homeless', 'migrant', 'disability', 'econ_disadvantaged', 'foster_care', 'military_connected'\n",
    "         \n",
    "- From enrollment:\n",
    "        - grade\n",
    "        - race\n",
    "        - sex \n",
    "        - enrollment\n",
    "        \n",
    "- Look into Kappa statistic (provides the percent of accordance and it substracts a number that it happened by chance) and chi-square test of independence (this would allow to compare more than two features). Even for categorical variables, a correlation would still get us a number\n",
    "\n",
    "         \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta-squared, or eta, as an effect-size measure for the relationship of a categorical variable and a continuous variable.\n",
    "# -> categorical (multi) + continuous \n",
    "\n",
    "def correlation_ratio(categories, measurements):\n",
    "        fcat, _ = pd.factorize(categories)\n",
    "        cat_num = np.max(fcat)+1\n",
    "        y_avg_array = np.zeros(cat_num)\n",
    "        n_array = np.zeros(cat_num)\n",
    "        for i in range(0,cat_num):\n",
    "            cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
    "            n_array[i] = len(cat_measures)\n",
    "            y_avg_array[i] = np.average(cat_measures)\n",
    "        y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
    "        numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
    "        denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
    "        if numerator == 0:\n",
    "            eta = 0.0\n",
    "        else:\n",
    "            eta = numerator/denominator\n",
    "        return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for Pearson correlation, which may not be applicable for our type of variables. \n",
    "\n",
    "correlations = smokers[\n",
    "    (smokers[\"charges\"] >= charges.quantile(q=0.25))\n",
    "    & (smokers[\"charges\"] <= charges.quantile(q=0.75))\n",
    "]\n",
    "corr = central.corr()\n",
    "corr.style.background_gradient(cmap=\"coolwarm\").set_precision(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
